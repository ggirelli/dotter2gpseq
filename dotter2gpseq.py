#!/usr/bin/env python
# -*- coding: utf-8 -*-

# ------------------------------------------------------------------------------
# 
# Author: Gabriele Girelli
# Email: gigi.ga90@gmail.com
# Version: 3.1.1
# Date: 20170718
# Project: GPSeq
# Description: Calculate radial position of dots in cells
# 
# Changelog:
#  v3.2.0 - 20171212: fixed G1 selection in output table.
#  v3.1.1 - 20171206: fixed allele polarity, using correct center of mass.
#  v3.1.0 - 20171204: fixed allele polarity including aspect ratio.
#  v3.0.1 - 20171130: adjusted allele polarity, fixed selection,
#                     also now allowing missing images.
#  v3.0.0 - 20171120: changed dilation to allow anisotropic images.
#  v2.3.1 - 20171120: fixed dilation factor (now corresponds to number of px).
#  v2.3.0 - 20171120: fixed allele angle calculation and minor bug.
#  v2.2.1 - 20171116: fixed series ID issue, added version column.
#  v2.2.0 - 20171116: added polarity calculation between alleles.
#  v2.1.0 - 20171115: fixed distance calculation and normalization.
#  v2.0.0 - 20171114: fixed cell assignment and G1 selection.
#  v1.2.0 - 20171105: dilation, allele labeling, parallelization.
#  v1.1.1 - 20171020: fixed parameter description.
#  v1.1.0 - 20170830: added G1 cells selection.
#  v1.0.0 - 20170718: first implementation.
# 
# ------------------------------------------------------------------------------



# DEPENDENCIES =================================================================

import argparse
from joblib import Parallel, delayed
import math
import matplotlib
matplotlib.use('ps')
import matplotlib.pyplot as plt
import multiprocessing
import numpy as np
import os
import pandas as pd
import pickle
from scipy.ndimage.measurements import center_of_mass
from scipy.ndimage.morphology import distance_transform_edt
import skimage.io as io
from skimage.measure import label
from skimage.morphology import dilation, cube
import sys

import pygpseq as gp
from pygpseq.wraps.nucleus import Nucleus
from pygpseq.tools import image as imt
from pygpseq.tools import io as iot
from pygpseq.tools import plot
from pygpseq.tools import stat as stt

# PARAMETERS ===================================================================

# Add script description
parser = argparse.ArgumentParser(description = '''
Calculate radial position of dots in cells. The G1 selection is actually a
selection of the most represented cell sub-population based on flatten area and
integral of DNA stain intensity. In other words, it will selected the most
represented cell cycle phase in your cell population (generally, G1). Images
are expected to follow DOTTER filename notation: "channel_series.tif".
''')

# Add mandatory arguments
parser.add_argument('dotCoords', type = str, nargs = 1,
    help = 'Dot coordinates table generated by DOTTER.')
parser.add_argument('imgFolder', type = str, nargs = 1,
    help = 'Path to folder containing deconvolved tiff images.')
parser.add_argument('outFolder', type = str, nargs = 1,
    help = 'Path to output folder (created if does not exist).')

# Optional parameters
parser.add_argument('-a', '--aspect', type = float, nargs = 3,
    help = """Physical size of Z, Y and X voxel sides.
    Default: 300.0 130.0 130.0""",
    metavar = ('Z', 'Y', 'X'), default = [300., 130., 130.])
parser.add_argument('-d', '--delim', type = str, nargs = 1,
    help = """Input table delimiter. Default: ','""", default = [','])
parser.add_argument('--dilate', type = int, nargs = 1,
    help = """Number of pixels for nuclear mask dilation. It is automatically
    scaled based on the specified aspect to be isotropic in 3D. Default: 0""",
    default = [0])
parser.add_argument('-t', '--threads', type = int, nargs = 1,
    help = """Number of threads for parallelization. Default: 1""",
    default = [1])

# Add flags
parser.add_argument('--noplot',
    action = 'store_const', dest = 'noplot',
    const = True, default = False,
    help = 'Do not produce any plots.')

# Version flag
version = "3.2.0"
parser.add_argument('--version', action = 'version',
    version = '%s v%s' % (sys.argv[0], version,))

# Parse arguments
args = parser.parse_args()

# Assign to in-script variables
dot_table_name = args.dotCoords[0]
dot_file_name = dot_table_name.split('/')[-1]
imdir = args.imgFolder[0]
aspect = args.aspect
(az, ay, ax) = aspect
outdir = args.outFolder[0]
delim = args.delim[0]
noplot = args.noplot
dilate_factor = args.dilate[0]
ncores = args.threads[0]

# Params
seg_type = gp.const.SEG_3D
an_type = gp.const.AN_3D

# Additional checks
if not outdir[-1] == "/":
    while not os.path.isdir(outdir) and os.path.exists(outdir):
        outdir += "_"
    outdir += "/"
if not imdir[-1] in ['/\\']:
    imdir += "/"
maxncores = multiprocessing.cpu_count()
if maxncores < ncores:
    print("Lowered number of threads to maximum available: %d" % (maxncores))
    ncores = maxncores
if 0 != dilate_factor and ax != ay:
    print("Cannot apply dilation on images with different X/Y aspect.")
    sys.exit()

# FUNCTIONS ====================================================================

def mkIsoStruct(dilate_factor, aspect):
    # Builds isotropic structuring element for dilation.
    #
    # Args:
    #   dilate_factor (int): number of px for isotropic 2D dilation.
    #   aspect (tuple(float)): voxel side ratios.
    # 
    # Returns:
    #   np.ndarray: structureing element for 3D anisotropic dilation.
    
    # Dilation factors
    df_xy = int(dilate_factor * 2 + 1)
    df_z = int(dilate_factor * aspect[1] / aspect[0] * 2 + 1)

    if df_z == df_xy:
        # Isotropic
        return(cube(df_z))
    elif df_z > df_xy:
        # Larger Z side
        se = cube(df_z)
        se = se[:, 0:df_xy, 0:df_xy]
    else:
        # Larger XY side
        se = cube(df_xy)
        se = se[0:df_z]

    # Output
    return(se)

def in_mask(coords, imbin):
    '''Check if a pixel in a mask is foreground.'''
    
    # Check the pixel is inside the image boundaries
    inbound = imbin.shape[0] > coords[0]
    inbound = inbound and imbin.shape[1] > coords[1]
    inbound = inbound and imbin.shape[2] > coords[2]
    inbound = inbound and all(np.array(coords) >= 0)
    if not inbound:
        return(False)

    # Check the pixel is foreground
    return(1 == imbin[coords[0], coords[1], coords[2]])

def in_box(coords, box):
    ''''''
    c = True
    for dim in range(len(coords)):
        c = c and coords[dim] >= box[dim][0] and coords[dim] <= box[dim][1]

    return c

def in_nucleus(n, s, coords):
    ''''''
    if not n.s == s:
        return False
    
    return in_box(coords, n.box)

def save_mask_png(outpath, im, name, title):
    fig = plt.figure()
    if 3 == len(im.shape):
        plt.imshow(im.max(0).astype('u4'))
    else:
        plt.imshow(im.astype('u4'))
    plt.gca().get_xaxis().set_visible(False)
    plt.gca().get_yaxis().set_visible(False)
    plot.set_font_size(8)

    plt.title(title)

    # Export as png
    if not noplot: plot.export(outpath, 'png')

    # Close plot figure
    plt.close(fig)

def in_3d_box(box, coords):
    # Check if point is in a box
    # 
    # Args:
    #   box (tuple): ((x0, x1), (y0, y1), (z0, z1)).
    #   coords (tuple): (x, y, z).
    # 
    # Returns
    #   bool
    cx = coords[0] >= box[0][0] and coords[0] <= box[0][1]
    cy = coords[1] >= box[1][0] and coords[1] <= box[1][1]
    cz = coords[2] >= box[2][0] and coords[2] <= box[2][1]
    return(cx and cy and cz)

def build_nuclei(msg, L, dilate_factor, series_id, thr, dna_bg, sig_bg,
    aspect, offset, logpath, i):
    # Build nuclei objects
    # 
    # Args:
    #   msg (string): log message, to be continued.
    #   L (np.ndarray): labeled mask.
    #   dilate_factor (int): dilation factor.
    #   series_id (int): series ID.
    #   thr (float): global threshold value.
    #   dna_bg (float): DNA channel background.
    #   sig_bg (float): signal channel background.
    #   aspect (tuple): Z,Y,X voxel sides in real units.
    #   offset (tuple): tuple with pixel offset for bounding box.
    #   logpath (string): path to log file.
    #   i (np.array): image.
    # 
    # Returns:
    #   (string, list): log message and list of Nucleus objects.
    
    # Prepare input for Nucleus class
    kwargs = {
        'series_id' : series_id, 'thr' : thr,
        'dna_bg' : dna_bg, 'sig_bg' : sig_bg,
        'aspect' : aspect, 'offset' : offset,
        'logpath' : logpath, 'i' : i
    }

    # Default nuclear ID list and empty dictionary
    seq = range(1, L.max() + 1)
    curnuclei = {}

    # Log operation
    if 0 != dilate_factor:
        msg += "   - Saving %d nuclei with dilation [%d]...\n" % (
            L.max(), dilate_factor)
    else:
        msg += "   - Saving %d nuclei...\n" % (L.max(),)

    # Iterate through nuclei
    for n in seq:
        # Make nucleus
        if 0 != dilate_factor:
            # With dilated mask
            mask = dilation(L == n, istruct)
            nucleus = Nucleus(n = n, mask = mask, **kwargs)
        else:
            mask = L == n
            nucleus = Nucleus(n = n, mask = mask, **kwargs)

        # Apply box
        msg += "    > Applying nuclear box [%d]...\n" % (n,)
        mask = imt.apply_box(mask, nucleus.box)

        # Store nucleus
        nucleus.mask = mask
        nucleus.box_origin = np.array([c[0] + 1 for c in nucleus.box])
        nucleus.box_sides = np.array([np.diff(c) for c in nucleus.box])
        nucleus.box_mass_center = center_of_mass(mask)
        nucleus.dilate_factor = dilate_factor
        curnuclei[n] = nucleus

    return((msg, curnuclei))

def dots2cells(t, nuclei, imbin, dilate_factor):
    # Assign dots to cells
    # 
    # Args:
    #   t (pd.DataFrame): DOTTER output subset.
    #   nuclei (list(gp.Nucleus)): identified nuclei.
    #   imbin (np.ndarray): binarized image.
    #   dilate_factor (int): number of dilation operations.
    # 
    # Returns:
    #   pd.DataFrame: updated DOTTER output.
    
    for idx in t.index:
        coords = ( t.loc[idx, 'z'], t.loc[idx, 'x'], t.loc[idx, 'y'] )
        for (nid, n) in nuclei.items():
            if in_mask(coords - n.box_origin, n.mask):
                t.loc[idx, 'cell_ID'] = nid
                continue

    # Output
    return(t)

def calc_dot_distances(msg, t, nuclei, aspect):
    # Calculate distance of dots from lamina and central area
    # 
    # Args:
    #   msg (string): log message, to be continued.
    #   t (pd.DataFrame): DOTTER output table.
    #   nuclei (list(gp.Nucleus)): identified nuclei.
    #   aspect (tuple): Z,Y,X voxel sides in real units.
    # 
    # Returns:
    #   pd.DataFrame:.

    # Calculate distances ------------------------------------------------------
    for cid in range(int(t['cell_ID'].max()) + 1):
        if cid in nuclei.keys():
                msg += "    >>> Working on cell #%d...\n" % (cid,)
                cell_cond = cid == t['cell_ID']

                # Distance from lamina and center
                laminD = distance_transform_edt(nuclei[cid].mask, aspect)
                centrD = distance_transform_edt(laminD != laminD.max(), aspect)

                t.loc[cell_cond, 'lamin_dist'] = laminD[
                    t.loc[cell_cond, 'z'] - nuclei[cid].box_origin[0],
                    t.loc[cell_cond, 'x'] - nuclei[cid].box_origin[1],
                    t.loc[cell_cond, 'y'] - nuclei[cid].box_origin[2]
                ]

                t.loc[cell_cond, 'centr_dist'] = centrD[
                    t.loc[cell_cond, 'z'] - nuclei[cid].box_origin[0],
                    t.loc[cell_cond, 'x'] - nuclei[cid].box_origin[1],
                    t.loc[cell_cond, 'y'] - nuclei[cid].box_origin[2]
                ]

    # Normalize distances ------------------------------------------------------

    # Max distance for each dot
    fnorm = t.loc[:, 'lamin_dist'] + t.loc[:, 'centr_dist']
    t.loc[:, 'centr_dist_norm'] = t.loc[:, 'centr_dist'] / fnorm
    t.loc[:, 'lamin_dist_norm'] = t.loc[:, 'lamin_dist'] / fnorm

    # Output
    return(t)

def flag_G1_cells(t, nuclei, outdir, dilate_factor, dot_file_name):
    # Assign a binary flag identifying the predominant cell population
    # based on flatten size and intensity sum
    # 
    # Args:
    #   t (pd.DataFrame): DOTTER output table.
    #   nuclei (list(gp.Nucleus)): identified nuclei.
    #   outdir (string): path to output folder.
    #   dilate_factor (int): number of dilation operations.
    #   dot_file_name (string): output file name.
    # 
    # Returns:
    #   pd.DataFrame:.
    # 
    print("> Flagging G1 cells...")

    # Retrieve nuclei summaries ------------------------------------------------
    print('   > Retrieving nuclear summary...')
    summary = np.zeros(len(nuclei),
        dtype = gp.const.DTYPE_NUCLEAR_SUMMARY)
    for i in range(len(nuclei)):
        summary[i] = nuclei[i].get_summary()

    # Filter nuclei ------------------------------------------------------------
    print('   > Filtering nuclei based on flatten size and intensity...')
    cond_name = 'none'
    sigma = .1
    nsf = (gp.const.NSEL_FLAT_SIZE, gp.const.NSEL_SUMI)
    out_dir = '.'

    # Filter features
    sel_data = {}
    ranges = {}
    plot_counter = 1
    for nsfi in nsf:
        # Identify Nuclear Selection Feature
        nsf_field = gp.const.NSEL_FIELDS[nsfi]
        nsf_name = gp.const.NSEL_NAMES[nsfi]
        print('   >> Filtering %s...' % (nsf_name,))

        # Start building output
        d = {'data' : summary[nsf_field]}

        # Calculate density
        d['density'] = stt.calc_density(d['data'], sigma = sigma)

        # Identify range
        args = [d['density']['x'], d['density']['y']]
        d['fwhm_range'] = stt.get_fwhm(*args)
        ranges[nsf_name] = d['fwhm_range']

        # Plot
        sel_data[nsf_field] = d

    # Select based on range
    f = lambda x, r: x >= r[0] and x <= r[1]
    for nsfi in nsf:
        nsf_field = gp.const.NSEL_FIELDS[nsfi]
        nsf_name = gp.const.NSEL_NAMES[nsfi]
        print("   > Selecting range for %s ..." % (nsf_name,))

        # Identify nuclei in the FWHM range
        nsf_data = sel_data[nsf_field]
        nsf_data['sel'] = [f(i, nsf_data['fwhm_range'])
            for i in nsf_data['data']]
        sel_data[nsf_field] = nsf_data

    # Select those in every FWHM range
    print("   > Applying selection criteria")
    nsfields = [gp.const.NSEL_FIELDS[nsfi] for nsfi in nsf]
    selected = [sel_data[f]['sel'] for f in nsfields]
    g = lambda i: all([sel[i] for sel in selected])
    selected = [i for i in range(len(selected[0])) if g(i)]
    sub_data = np.array(summary[selected])

    # Identify selected nuclei objects
    sel_nuclei_labels = ["_%d.%d_" % (n, s)
        for (n, s) in sub_data[['s', 'n']]]
    sel_nucl = [n for n in nuclei
        if "_%d.%d_" % (n.s, n.n) in sel_nuclei_labels]

    # Check which dots are in which nucleus and update flag --------------------
    print("   > Matching DOTTER cells with GPSeq cells...")
    t['G1'] = np.zeros((t.shape[0],))
    t['universalID'] =  ["_%s.%s_" % x for x in zip(
        t['File'].values, t['cell_ID'].astype('i').values
    )]
    g1ids = [i for i in range(t.shape[0])
        if t.loc[i, 'universalID'] in sel_nuclei_labels]
    t.loc[g1ids, 'G1'] = 1
    t = t.drop('universalID', 1)

    # Add G1 status to summary -------------------------------------------------
    summary = pd.DataFrame(summary)
    summary['G1'] = np.zeros((summary.shape[0],))
    summary['universalID'] =  ["_%s.%s_" % x
        for x in zip(summary['s'].values, summary['n'].values)]
    g1ids = [i for i in range(summary.shape[0])
        if summary.loc[i, 'universalID'] in sel_nuclei_labels]
    summary.loc[g1ids, 'G1'] = 1
    summary = summary.drop('universalID', 1)

    # Export -------------------------------------------------------------------

    # Export feature ranges
    s = ""
    for (k, v) in ranges.items():
        s += "%s\t%f\t%f\n" % (k, v[0], v[1])
    f = open("%s/feature_ranges.txt" % (outdir,), "w+")
    f.write(s)
    f.close()

    # Export summary
    outname = "%s/nuclei.out.dilate%d.%s" % (
        outdir, dilate_factor, dot_file_name)
    summary.to_csv(outname, sep = '\t', index = False)

    # Output -------------------------------------------------------------------
    print("> Flagged G1 cells...")
    return(t)

def add_allele(data):
    # Add allele labels to DOTTER-based table with GPSeq-like centrality.
    # 
    # Labels:
    #   NaN : dot outside of cells.
    #   -1  : more than 2 dots per cell.
    #   0   : less than 2 dots per cell.
    #   1   : central dot.
    #   2   : peripheral dot.
    # 
    # Args:
    #   data (pd.DataFrame): DOTTER-based table with GPSeq-like centrality.
    #                        Required columns:
    #                           cell_ID, lamin_dist_norm, File, Channel
    #
    # Returns:
    #   pd.DataFrame: input data table with added Allele column (label).
    # 

    # Initial checks -----------------------------------------------------------

    # Check that the format corresponds
    if not type(data) == type(pd.DataFrame()):
        print("Input should be a DataFrame from the pandas library.")
        return(data)

    # Check that required columns are present
    req_cols = ['cell_ID', 'lamin_dist_norm', 'File', 'Channel']
    check_cols = [True for c in req_cols if c in data.columns.tolist()]
    if not all(check_cols):
        miss_cols = [req_cols[i]
            for i in range(len(req_cols)) if not check_cols[i]]
        print("Some required columns are missing: %s" % (", ".join(miss_cols),))
        return(data)

    # Universal index and dots in cells ----------------------------------------

    # Identify dots within cells
    validIdx = np.nonzero(data['cell_ID'])[0]

    # Assemble universal index
    data['universalID'] =  ["%s_%s_%s" % t for t in zip(
        data['File'].values, data['Channel'].values, data['cell_ID'].values
    )]

    # Count dots per universalID
    uID,  uCount = np.unique(data.loc[validIdx, 'universalID'],
        return_index = False, return_counts = True)
    IDmap = zip(data.loc[validIdx, 'universalID'],
        [dict(zip(uID, uCount))[ID]
        for ID in data.loc[validIdx, 'universalID']])
    IDmap = np.array(list(IDmap))
    
    # Stop if now dots are inside a cell
    if 0 == sum(IDmap.shape):
        data['Allele'] = ''
        return(data.drop('universalID', 1))

    # Fill Allele column -------------------------------------------------------
    
    # Default value of np.nan for dots outside of nuclei
    data['Allele'] = np.nan

    # -1 if more than 2 dots
    cond = IDmap[:,1].astype('i') > 2
    if 0 != sum(cond):
        data.loc[validIdx[cond], 'Allele'] = -1

    #  0 if less than 2 dots
    cond = IDmap[:,1].astype('i') == 1
    if 0 != sum(cond):
        data.loc[validIdx[cond], 'Allele'] = 0

    # Iterate over 2-dots cases
    cond = IDmap[:,1].astype('i') == 2
    if 0 != sum(cond):
        uID = np.unique(IDmap[cond, 0]).tolist()
        for ID in uID:
            dotPair = data.loc[data['universalID'] == ID, :]
            ldn = dotPair['lamin_dist_norm'].tolist()
            if ldn[0] == ldn[1]:
                # Same centrality
                data.loc[dotPair.index[0], 'Allele'] = 1 # Central
                data.loc[dotPair.index[1], 'Allele'] = 2 # Peripheral
            else: # Different centrality
                # Peripheral
                data.loc[dotPair['lamin_dist_norm'].argmin(), 'Allele'] = 2
                # Central
                data.loc[dotPair['lamin_dist_norm'].argmax(), 'Allele'] = 1

    # Output -------------------------------------------------------------------
    return(data.drop('universalID', 1))

def angle_between_points( p0, c, p1 ):
    # c is the center point; result is in degrees
    # From http://phrogz.net/angle-between-three-points
    p0 = np.array(p0)
    c = np.array(c)
    p1 = np.array(p1)

    p0c = np.sqrt(np.sum((p0 - c)**2))
    p1c = np.sqrt(np.sum((p1 - c)**2))
    p01 = np.sqrt(np.sum((p0 - p1)**2))

    tetha = math.acos( (p0c**2 + p1c**2 - p01**2) / (2 * p0c * p1c) )

    return(tetha / math.pi * 180)

def analyze_field_of_view(ii, imfov, imdir, an_type, seg_type,
    maskdir, dilate_factor, aspect, t):
    # Logger for logpath
    logger = iot.IOinterface()

    idx = ii
    impath = imfov[ii]
    print("  Started '%s' job..." % (impath,))
    msg = "> Job '%s'...\n" % (impath,)
    subt_idx = np.where(t['File'] == idx)[0]

    # Read image
    msg += "   - Reading ...\n"
    im = io.imread(os.path.join(imdir, impath))
    if 1 == im.shape[0]:
        im = im[0]

    # Re-slice
    msg += "    > Re-slicing ...\n"
    im = imt.autoselect_time_frame(im)
    im = imt.slice_k_d_img(im, 3)

    # Get DNA scaling factor and rescale
    sf = imt.get_rescaling_factor([impath], basedir = imdir)
    im = (im / sf).astype('float')
    msg += "    > Re-scaling with factor %f...\n" % (sf,)

    # Pick first timeframe
    if 3 == len(im.shape) and 1 == im.shape[0]:
        im = im[0]

    # Binarize image -----------------------------------------------------------
    msg += "   - Binarizing...\n"
    binarization = gp.tools.binarize.Binarize(
        an_type=an_type,
        seg_type=seg_type,
        verbose = False
    )
    (imbin, thr, log) = binarization.run(im)
    msg += log

    # Find nuclei --------------------------------------------------------------
    msg += "   - Retrieving nuclei...\n"

    # Estimate background
    dna_bg = imt.estimate_background(im, imbin, seg_type)
    msg += "    > Estimated background: %.2f a.u.\n" % (dna_bg,)

    # Filter object size
    imbin, tmp = binarization.filter_obj_XY_size(imbin)
    imbin, tmp = binarization.filter_obj_Z_size(imbin)

    # Save default mask
    msg += "   - Saving default binary mask...\n"
    outname = "%smask.%s.default.png" % (maskdir, impath)
    save_mask_png(outname, imbin, impath, "Default mask.")

    # Export dilated mask
    if not noplot and 0 != dilate_factor:
        msg += "   - Saving dilated mask...\n"
        imbin_dil = dilation(imbin, istruct)
        #io.imsave("%sdilated.tif" % (maskdir,), imbin_dil.astype('u4'))
        title = "Dilated mask, %d factor." % (dilate_factor,)
        outname = "%smask.%s.dilated%d.png" % (maskdir, impath, dilate_factor)
        save_mask_png(outname, imbin_dil, impath, title)

    # Identify nuclei
    L = label(imbin)
    seq = range(1, L.max() + 1)

    # Save mask ----------------------------------------------------------------
    msg += "   - Saving nuclear ID mask...\n"
    title = 'Nuclei in "%s" [%d objects]' % (impath, im.max())
    outpath = "%smask.%s.nuclei.png" % (maskdir, impath)
    save_mask_png(outpath, L, impath, title)

    # Store nuclei -------------------------------------------------------------
    msg, curnuclei = build_nuclei(msg, L, dilate_factor,
        series_id = ii, thr = thr,
        dna_bg = dna_bg, sig_bg = 0,
        aspect = aspect, offset = (1, 1, 1),
        logpath = logger.logpath, i = im)

    # Assign dots to cells -----------------------------------------------------
    msg += "   - Analysis...\n"
    msg += "    > Assigning dots to cells...\n"
    subt = dots2cells(t.loc[subt_idx, :], curnuclei, imbin, dilate_factor)

    # Distances ----------------------------------------------------------------
    msg += "    > Calculating lamina distance...\n"
    subt = calc_dot_distances(msg, subt, curnuclei, aspect)

    # Clean and output ---------------------------------------------------------

    # Remove masks from curnuclei
    for k in curnuclei.keys():
        del curnuclei[k].mask

    # Output
    msg += "< Finished job."
    print(msg)
    return((curnuclei, subt, subt_idx))

# RUN ==========================================================================

# Create output folder
if not os.path.isdir(outdir):
    os.mkdir(outdir)

# Create mask directory
maskdir = outdir + "masks/"
if not os.path.isdir(maskdir):
    os.mkdir(maskdir)

# Build 3D isotropic structuring element for dilation
istruct = mkIsoStruct(dilate_factor, (az, ay, ax))
if az != ax:
    t = np.array(istruct.shape) / 2
    msg = "  Anisotropic dilation of "
    msg += "(%d, %d, %d) px in ZYX, respectively." % tuple(t.tolist())
    print(msg)

# Input ------------------------------------------------------------------------

# Read table
t = pd.read_csv(dot_table_name, delim)

# Add new empty columns
t['cell_ID'] = np.zeros(len(t.index))
t['lamin_dist'] = np.zeros(len(t.index))
t['lamin_dist_norm'] = np.zeros(len(t.index))
t['centr_dist'] = np.zeros(len(t.index))
t['centr_dist_norm'] = np.zeros(len(t.index))
t['dilation'] = dilate_factor
t['angle'] = np.zeros(len(t.index))
t['com'] = "_"
t['version'] = version

# Identify images --------------------------------------------------------------

# Extract FoV number
t['File'] = [int(f.split('/')[-1].split('.')[0]) for f in t['File']]

# Identify tiff images
flist = []
for (dirpath, dirnames, filenames) in os.walk(imdir):
    flist.extend(filenames)
    break
imlist = [f for f in flist if 'tif' in f]

# Assign field of views to images
imfov = {}
for i in set(t['File']):
    imsel = [im for im in imlist if "%03d" % (i,) in im]
    if not 0 == len(imsel):
        imfov[i] = imsel[0]
    else:
        print("  Missing image for field #%d, skipped." % (i,))

# Start iteration --------------------------------------------------------------

# Nuclei container
nuclei = []

# Cycle through
kwargs = {
    'imfov' : imfov, 'imdir' : imdir,
    'an_type' : an_type, 'seg_type' : seg_type, 'maskdir' : maskdir,
    'dilate_factor' : dilate_factor, 'aspect' : aspect, 't' : t
}
anData = Parallel(n_jobs = ncores)(
    delayed(analyze_field_of_view)(ii, **kwargs)
    for ii in set(imfov.keys()))
for (curnuclei, subt, subt_idx) in anData:
    nuclei.extend(curnuclei.values())
    t.loc[subt_idx, :] = subt

# Identify G1 cells ------------------------------------------------------------
t = flag_G1_cells(t, nuclei, outdir, dilate_factor, dot_file_name)

# Export -----------------------------------------------------------------------

# Export nuclei object vector
f = open("%s/nuclei.pickle" % (outdir,), "wb+")
pickle.dump(nuclei, f)
f.close()

# Export table before allele labeling
outname = "%s/wCentr.out.noAllele.dilate%d.%s" % (
    outdir, dilate_factor, dot_file_name)
t.to_csv(outname, sep = '\t', index = False)

# Add allele information -------------------------------------------------------
print("  - Adding allele information...")
t = add_allele(t)

# Calculate angle on nucleus centroid between alleles --------------------------
print("  - Adding allele polarity information...")

# Assemble universal index
t.loc[:, 'universalID'] = ["%s_%s_%s" % x for x in zip(
    t['File'].values, t['Channel'].values, t['cell_ID'].values
)]

# Subset data
subt = t.loc[t['Allele'] > 0,:]

# Go through cells
for uid in subt['universalID']:
    idx = subt[subt['universalID'] == uid].index

    # Retrieve allele coordinates
    focus = subt.loc[subt['universalID'] == uid, ('x', 'y', 'z')]
    if 0 == sum(focus.shape):
        continue

    # Identify nucleus
    cell_ID = subt.loc[subt['universalID'] == uid, 'cell_ID'].values[0]
    series_ID = subt.loc[subt['universalID'] == uid, 'File'].values[0]
    nucleus = [n for n in nuclei if n.s == series_ID and n.n == cell_ID]
    if 0 == len(nucleus):
        print("Nucleus not found for %s.%s" % (series_ID, cell_ID,))
        continue
    else:
        nucleus = nucleus[0]

    # Nucleus center of mass coordinates
    centr_coords = (nucleus.box_mass_center + nucleus.box_origin).astype('i')
    # Re-order center of mass coordinates
    centr_coords = centr_coords[[1, 2, 0]]

    # Calculate angle
    xyz_aspect = np.array((ax, ay, az))
    t.loc[idx, 'angle'] = angle_between_points(
        focus.loc[focus.index[0],:] * xyz_aspect,
        centr_coords * xyz_aspect,
        focus.loc[focus.index[1],:] * xyz_aspect
    )
    t.loc[idx, 'com'] = "_".join([str(x) for x in centr_coords.tolist()])

# Remove universal ID
t = t.drop('universalID', 1)

# Write output -----------------------------------------------------------------
outname = "%s/wCentr.out.dilate%d.%s" % (
    outdir, dilate_factor, dot_file_name)
t.to_csv(outname, sep = '\t', index = False)

# END ==========================================================================

################################################################################
